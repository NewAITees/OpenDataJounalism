"""
e-stat ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
å®Ÿéš›ã®e-statçµ±è¨ˆè¡¨æƒ…å ±ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»ç®¡ç†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import json
import os
import requests
import xml.etree.ElementTree as ET
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from dotenv import load_dotenv
import sqlite3
from datetime import datetime


class EstatMetadataLoader:
    """e-statçµ±è¨ˆè¡¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data_dir: str = "data/mcp"):
        load_dotenv()
        self.appid = os.getenv("ESTAT_APPID")
        if not self.appid:
            raise ValueError("ESTAT_APPIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        self.metadata_db = self.data_dir / "estat_metadata.db"
        self._init_metadata_db()
        
        # e-stat API ã®ãƒ™ãƒ¼ã‚¹URL
        self.api_base = "https://api.e-stat.go.jp/rest/3.0/app"
    
    def _init_metadata_db(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        # çµ±è¨ˆè¡¨ãƒªã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS stats_tables (
                table_id TEXT PRIMARY KEY,
                stat_id TEXT,
                gov_org TEXT,
                stat_name TEXT,
                title TEXT,
                cycle TEXT,
                survey_date TEXT,
                open_date TEXT,
                small_area INTEGER,
                main_category_code TEXT,
                main_category TEXT,
                sub_category_code TEXT,
                sub_category TEXT,
                overall_total_number INTEGER,
                updated_date TEXT
            )
        ''')
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå„çµ±è¨ˆè¡¨ã®è©³ç´°è»¸æƒ…å ±ï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS table_metadata (
                table_id TEXT,
                class_obj_id TEXT,
                class_obj_name TEXT,
                class_name TEXT,
                level TEXT,
                unit TEXT,
                PRIMARY KEY (table_id, class_obj_id)
            )
        ''')
        
        # ã‚¯ãƒ©ã‚¹å€¤ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå„è»¸ã®å…·ä½“çš„ãªå€¤ï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS class_values (
                table_id TEXT,
                class_obj_id TEXT,
                class_code TEXT,
                class_name TEXT,
                level TEXT,
                parent_code TEXT,
                PRIMARY KEY (table_id, class_obj_id, class_code)
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def fetch_all_stats_tables(self, limit: int = 10000) -> List[Dict]:
        """å…¨çµ±è¨ˆè¡¨ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—"""
        print(f"ğŸ“Š e-statã‹ã‚‰çµ±è¨ˆè¡¨ãƒªã‚¹ãƒˆã‚’å–å¾—ä¸­ï¼ˆæœ€å¤§{limit}ä»¶ï¼‰...")
        
        try:
            url = f"{self.api_base}/getStatsList"
            params = {
                "appId": self.appid,
                "limit": limit,
                "searchWord": "",  # æ¤œç´¢èªãªã—ã§å…¨çµ±è¨ˆè¡¨ã‚’å–å¾—
                "collect": "Y"     # åé›†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ã¿
            }
            
            response = requests.get(url, params=params, timeout=60)
            response.raise_for_status()
            
            # XMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            root = ET.fromstring(response.text)
            
            # DATALIST_INFè¦ç´ ã‚’æ¢ã™
            datalist_inf = root.find(".//DATALIST_INF")
            if datalist_inf is None:
                print("çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return []
            
            # TABLE_INFè¦ç´ ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            table_infos = datalist_inf.findall("TABLE_INF")
            stats_tables = []
            
            for table_inf in table_infos:
                table_data = {}
                for child in table_inf:
                    table_data[child.tag] = child.text if child.text else ""
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ç”¨ã«æ•´ç†
                processed_table = {
                    'table_id': table_data.get('TABLE_INF', ''),
                    'stat_id': table_data.get('STAT_NAME_CODE', ''),
                    'gov_org': table_data.get('GOV_ORG', ''),
                    'stat_name': table_data.get('STAT_NAME', ''),
                    'title': table_data.get('TITLE', ''),
                    'cycle': table_data.get('CYCLE', ''),
                    'survey_date': table_data.get('SURVEY_DATE', ''),
                    'open_date': table_data.get('OPEN_DATE', ''),
                    'small_area': 1 if table_data.get('SMALL_AREA') == '1' else 0,
                    'main_category_code': table_data.get('MAIN_CATEGORY_CODE', ''),
                    'main_category': table_data.get('MAIN_CATEGORY', ''),
                    'sub_category_code': table_data.get('SUB_CATEGORY_CODE', ''),
                    'sub_category': table_data.get('SUB_CATEGORY', ''),
                    'overall_total_number': int(table_data.get('OVERALL_TOTAL_NUMBER', 0)) if table_data.get('OVERALL_TOTAL_NUMBER') else 0,
                    'updated_date': datetime.now().isoformat()
                }
                
                stats_tables.append(processed_table)
            
            print(f"âœ… {len(stats_tables)}ä»¶ã®çµ±è¨ˆè¡¨æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ")
            return stats_tables
            
        except Exception as e:
            print(f"çµ±è¨ˆè¡¨ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def fetch_table_metadata(self, table_id: str) -> Dict:
        """ç‰¹å®šçµ±è¨ˆè¡¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè»¸æƒ…å ±ï¼‰ã‚’å–å¾—"""
        print(f"ğŸ” çµ±è¨ˆè¡¨ {table_id} ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        try:
            url = f"{self.api_base}/getMetaInfo"
            params = {
                "appId": self.appid,
                "statsDataId": table_id
            }
            
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            # XMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            root = ET.fromstring(response.text)
            
            metadata = {
                'table_id': table_id,
                'class_objects': [],
                'class_values': {}
            }
            
            # CLASS_INFè¦ç´ ã‚’æ¢ã™
            class_infs = root.findall(".//CLASS_INF")
            
            for class_inf in class_infs:
                class_obj = {}
                
                # CLASS_OBJè¦ç´ ã®æƒ…å ±
                class_obj_elem = class_inf.find("CLASS_OBJ")
                if class_obj_elem is not None:
                    class_obj['id'] = class_obj_elem.get('id', '')
                    class_obj['name'] = class_obj_elem.get('name', '')
                    
                    # CLASSè¦ç´ ã®æƒ…å ±
                    class_elem = class_obj_elem.find("CLASS")
                    if class_elem is not None:
                        class_obj['class_name'] = class_elem.get('name', '')
                        class_obj['level'] = class_elem.get('level', '')
                        class_obj['unit'] = class_elem.get('unit', '')
                
                # CLASS_VALUEè¦ç´ ã®å€¤ä¸€è¦§
                class_values = []
                class_value_elems = class_inf.findall(".//CLASS_VALUE")
                
                for class_value in class_value_elems:
                    value_info = {
                        'code': class_value.get('code', ''),
                        'name': class_value.get('name', ''),
                        'level': class_value.get('level', ''),
                        'parent_code': class_value.get('parentCode', '')
                    }
                    class_values.append(value_info)
                
                metadata['class_objects'].append(class_obj)
                metadata['class_values'][class_obj.get('id', '')] = class_values
            
            return metadata
            
        except Exception as e:
            print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ï¼ˆ{table_id}ï¼‰: {e}")
            return {}
    
    def save_stats_tables_to_db(self, stats_tables: List[Dict]):
        """çµ±è¨ˆè¡¨ãƒªã‚¹ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        for table in stats_tables:
            cursor.execute('''
                INSERT OR REPLACE INTO stats_tables 
                (table_id, stat_id, gov_org, stat_name, title, cycle, survey_date, 
                 open_date, small_area, main_category_code, main_category, 
                 sub_category_code, sub_category, overall_total_number, updated_date)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                table['table_id'], table['stat_id'], table['gov_org'], 
                table['stat_name'], table['title'], table['cycle'], 
                table['survey_date'], table['open_date'], table['small_area'],
                table['main_category_code'], table['main_category'],
                table['sub_category_code'], table['sub_category'],
                table['overall_total_number'], table['updated_date']
            ))
        
        conn.commit()
        conn.close()
        print(f"ğŸ’¾ {len(stats_tables)}ä»¶ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def save_table_metadata_to_db(self, metadata: Dict):
        """çµ±è¨ˆè¡¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        table_id = metadata['table_id']
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
        for class_obj in metadata.get('class_objects', []):
            cursor.execute('''
                INSERT OR REPLACE INTO table_metadata 
                (table_id, class_obj_id, class_obj_name, class_name, level, unit)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                table_id, class_obj.get('id', ''), class_obj.get('name', ''),
                class_obj.get('class_name', ''), class_obj.get('level', ''),
                class_obj.get('unit', '')
            ))
        
        # ã‚¯ãƒ©ã‚¹å€¤ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
        for class_obj_id, class_values in metadata.get('class_values', {}).items():
            for value in class_values:
                cursor.execute('''
                    INSERT OR REPLACE INTO class_values 
                    (table_id, class_obj_id, class_code, class_name, level, parent_code)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (
                    table_id, class_obj_id, value.get('code', ''),
                    value.get('name', ''), value.get('level', ''),
                    value.get('parent_code', '')
                ))
        
        conn.commit()
        conn.close()
        print(f"ğŸ’¾ çµ±è¨ˆè¡¨ {table_id} ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    
    def load_all_stats_for_ollama(self) -> Dict:
        """Ollamaç”¨ã«å…¨çµ±è¨ˆè¡¨æƒ…å ±ã‚’æ•´ç†ã—ã¦è¿”ã™"""
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        # çµ±è¨ˆè¡¨åŸºæœ¬æƒ…å ±ã‚’å–å¾—
        cursor.execute('''
            SELECT table_id, stat_name, title, main_category, sub_category, 
                   gov_org, survey_date, overall_total_number
            FROM stats_tables
            ORDER BY main_category_code, sub_category_code
        ''')
        
        stats_tables = cursor.fetchall()
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†
        ollama_data = {
            "ç»Ÿè®¡è¡¨æ€»æ•°": len(stats_tables),
            "æœ€æ–°æ›´æ–°": datetime.now().strftime("%Y-%m-%d"),
            "åˆ†ç±»ç»Ÿè®¡è¡¨": {}
        }
        
        for table in stats_tables:
            table_id, stat_name, title, main_category, sub_category, gov_org, survey_date, total_num = table
            
            if main_category not in ollama_data["åˆ†ç±»ç»Ÿè®¡è¡¨"]:
                ollama_data["åˆ†ç±»ç»Ÿè®¡è¡¨"][main_category] = {}
            
            if sub_category not in ollama_data["åˆ†ç±»ç»Ÿè®¡è¡¨"][main_category]:
                ollama_data["åˆ†ç±»ç»Ÿè®¡è¡¨"][main_category][sub_category] = []
            
            # è»¸æƒ…å ±ã‚‚å–å¾—
            cursor.execute('''
                SELECT class_obj_id, class_obj_name, class_name, unit
                FROM table_metadata
                WHERE table_id = ?
            ''', (table_id,))
            
            axes_info = cursor.fetchall()
            axes = {}
            for axis in axes_info:
                axis_id, axis_name, class_name, unit = axis
                axes[axis_id] = {
                    "name": axis_name,
                    "class": class_name,
                    "unit": unit if unit else ""
                }
            
            table_info = {
                "ç»Ÿè®¡è¡¨ID": table_id,
                "ç»Ÿè®¡åç§°": stat_name,
                "è¡¨æ ‡é¢˜": title,
                "å®æ–½æœºå…³": gov_org,
                "è°ƒæŸ¥æ—¥æœŸ": survey_date,
                "æ•°æ®æ€»æ•°": total_num,
                "å¯ç”¨è½´": axes
            }
            
            ollama_data["åˆ†ç±»ç»Ÿè®¡è¡¨"][main_category][sub_category].append(table_info)
        
        conn.close()
        return ollama_data
    
    def get_table_axis_details(self, table_id: str) -> Dict:
        """ç‰¹å®šçµ±è¨ˆè¡¨ã®è»¸è©³ç´°æƒ…å ±ã‚’å–å¾—"""
        conn = sqlite3.connect(self.metadata_db)
        cursor = conn.cursor()
        
        # è»¸æƒ…å ±ã‚’å–å¾—
        cursor.execute('''
            SELECT class_obj_id, class_obj_name, class_name, unit
            FROM table_metadata
            WHERE table_id = ?
        ''', (table_id,))
        
        axes = cursor.fetchall()
        axis_details = {}
        
        for axis in axes:
            axis_id, axis_name, class_name, unit = axis
            
            # è©²å½“è»¸ã®å€¤ä¸€è¦§ã‚’å–å¾—
            cursor.execute('''
                SELECT class_code, class_name, level, parent_code
                FROM class_values
                WHERE table_id = ? AND class_obj_id = ?
                ORDER BY class_code
            ''', (table_id, axis_id))
            
            values = cursor.fetchall()
            value_list = []
            for value in values:
                code, name, level, parent = value
                value_list.append({
                    "code": code,
                    "name": name,
                    "level": level,
                    "parent": parent
                })
            
            axis_details[axis_id] = {
                "axis_name": axis_name,
                "class_name": class_name,
                "unit": unit,
                "values": value_list
            }
        
        conn.close()
        return axis_details
    
    def update_metadata_cache(self, max_tables: int = 100):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ›´æ–°"""
        print("ğŸ”„ e-stat ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ä¸­...")
        
        # 1. çµ±è¨ˆè¡¨ãƒªã‚¹ãƒˆã‚’å–å¾—ãƒ»ä¿å­˜
        stats_tables = self.fetch_all_stats_tables(limit=max_tables)
        if stats_tables:
            self.save_stats_tables_to_db(stats_tables)
        
        # 2. ä¸»è¦çµ±è¨ˆè¡¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆäººå£ãƒ»åŠ´åƒé–¢é€£å„ªå…ˆï¼‰
        priority_keywords = ["äººå£", "åŠ´åƒ", "ä¸–å¸¯", "å®¶è¨ˆ", "å›½å‹¢"]
        priority_tables = []
        
        for table in stats_tables:
            if any(keyword in table.get('stat_name', '') or keyword in table.get('title', '') 
                   for keyword in priority_keywords):
                priority_tables.append(table['table_id'])
        
        print(f"ğŸ¯ å„ªå…ˆçµ±è¨ˆè¡¨ {len(priority_tables[:20])}ä»¶ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        for i, table_id in enumerate(priority_tables[:20]):  # ä¸Šä½20ä»¶ã®ã¿
            print(f"  {i+1}/20: {table_id}")
            metadata = self.fetch_table_metadata(table_id)
            if metadata:
                self.save_table_metadata_to_db(metadata)
        
        print("âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("=== e-stat ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ ===")
    
    loader = EstatMetadataLoader()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ›´æ–°
    loader.update_metadata_cache(max_tables=200)
    
    # Ollamaç”¨ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
    ollama_data = loader.load_all_stats_for_ollama()
    print(f"\nOllamaç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†:")
    print(f"  çµ±è¨ˆè¡¨ç·æ•°: {ollama_data['ç»Ÿè®¡è¡¨æ€»æ•°']}")
    print(f"  ã‚«ãƒ†ã‚´ãƒªæ•°: {len(ollama_data['åˆ†ç±»ç»Ÿè®¡è¡¨'])}")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    for category, subcategories in list(ollama_data['åˆ†ç±»ç»Ÿè®¡è¡¨'].items())[:3]:
        print(f"  ğŸ“Š {category}: {sum(len(tables) for tables in subcategories.values())}ä»¶")


if __name__ == "__main__":
    main()