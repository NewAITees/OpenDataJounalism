"""
e-stat AI Query Translator MCP
è‡ªç„¶è¨€èªã®è¦æœ›ã‚’e-stat APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹ãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½
"""

import json
import re
import sqlite3
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import pandas as pd


@dataclass
class QueryResult:
    """ã‚¯ã‚¨ãƒªå¤‰æ›çµæœ"""
    stats_data_id: str
    parameters: Dict[str, str]
    description: str
    confidence_score: float
    table_name: str
    alternative_suggestions: List['QueryResult'] = None

    def __post_init__(self):
        if self.alternative_suggestions is None:
            self.alternative_suggestions = []


@dataclass
class EntitySet:
    """æŠ½å‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æƒ…å ±"""
    regions: List[str]
    time_periods: List[str]
    categories: List[str]
    statistical_items: List[str]


class EstatQueryTranslator:
    """e-statè‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªå¤‰æ›å™¨"""
    
    def __init__(self, data_dir: Optional[Path] = None, use_ollama: bool = True):
        self.data_dir = data_dir or Path("data/mcp")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.use_ollama = use_ollama
        
        # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
        self._init_knowledge_base()
        
        # Ollamaçµ±åˆã®åˆæœŸåŒ–
        if use_ollama:
            try:
                from .ollama_integration import OllamaStatsMCP
                self.ollama_mcp = OllamaStatsMCP()
                print(f"âœ… Ollamaçµ±åˆã‚’æœ‰åŠ¹åŒ–: {self.ollama_mcp.available}")
            except ImportError:
                print("âš ï¸ Ollamaçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¨¡å¼ã§å‹•ä½œã—ã¾ã™ã€‚")
                self.ollama_mcp = None
        else:
            self.ollama_mcp = None
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        self.db_path = self.data_dir / "catalog_index.db"
        self._init_database()
    
    def _init_knowledge_base(self):
        """çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        # åœ°åŸŸã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        self.area_mappings = {
            "å…¨å›½": "00000",
            "åŒ—æµ·é“": "01000",
            "é’æ£®": "02000", "é’æ£®çœŒ": "02000",
            "å²©æ‰‹": "03000", "å²©æ‰‹çœŒ": "03000",
            "å®®åŸ": "04000", "å®®åŸçœŒ": "04000",
            "ç§‹ç”°": "05000", "ç§‹ç”°çœŒ": "05000",
            "å±±å½¢": "06000", "å±±å½¢çœŒ": "06000",
            "ç¦å³¶": "07000", "ç¦å³¶çœŒ": "07000",
            "èŒ¨åŸ": "08000", "èŒ¨åŸçœŒ": "08000",
            "æ ƒæœ¨": "09000", "æ ƒæœ¨çœŒ": "09000",
            "ç¾¤é¦¬": "10000", "ç¾¤é¦¬çœŒ": "10000",
            "åŸ¼ç‰": "11000", "åŸ¼ç‰çœŒ": "11000",
            "åƒè‘‰": "12000", "åƒè‘‰çœŒ": "12000",
            "æ±äº¬": "13000", "æ±äº¬éƒ½": "13000",
            "ç¥å¥ˆå·": "14000", "ç¥å¥ˆå·çœŒ": "14000",
            "æ–°æ½Ÿ": "15000", "æ–°æ½ŸçœŒ": "15000",
            "å¯Œå±±": "16000", "å¯Œå±±çœŒ": "16000",
            "çŸ³å·": "17000", "çŸ³å·çœŒ": "17000",
            "ç¦äº•": "18000", "ç¦äº•çœŒ": "18000",
            "å±±æ¢¨": "19000", "å±±æ¢¨çœŒ": "19000",
            "é•·é‡": "20000", "é•·é‡çœŒ": "20000",
            "å²é˜œ": "21000", "å²é˜œçœŒ": "21000",
            "é™å²¡": "22000", "é™å²¡çœŒ": "22000",
            "æ„›çŸ¥": "23000", "æ„›çŸ¥çœŒ": "23000",
            "ä¸‰é‡": "24000", "ä¸‰é‡çœŒ": "24000",
            "æ»‹è³€": "25000", "æ»‹è³€çœŒ": "25000",
            "äº¬éƒ½": "26000", "äº¬éƒ½åºœ": "26000",
            "å¤§é˜ª": "27000", "å¤§é˜ªåºœ": "27000",
            "å…µåº«": "28000", "å…µåº«çœŒ": "28000",
            "å¥ˆè‰¯": "29000", "å¥ˆè‰¯çœŒ": "29000",
            "å’Œæ­Œå±±": "30000", "å’Œæ­Œå±±çœŒ": "30000",
            "é³¥å–": "31000", "é³¥å–çœŒ": "31000",
            "å³¶æ ¹": "32000", "å³¶æ ¹çœŒ": "32000",
            "å²¡å±±": "33000", "å²¡å±±çœŒ": "33000",
            "åºƒå³¶": "34000", "åºƒå³¶çœŒ": "34000",
            "å±±å£": "35000", "å±±å£çœŒ": "35000",
            "å¾³å³¶": "36000", "å¾³å³¶çœŒ": "36000",
            "é¦™å·": "37000", "é¦™å·çœŒ": "37000",
            "æ„›åª›": "38000", "æ„›åª›çœŒ": "38000",
            "é«˜çŸ¥": "39000", "é«˜çŸ¥çœŒ": "39000",
            "ç¦å²¡": "40000", "ç¦å²¡çœŒ": "40000",
            "ä½è³€": "41000", "ä½è³€çœŒ": "41000",
            "é•·å´": "42000", "é•·å´çœŒ": "42000",
            "ç†Šæœ¬": "43000", "ç†Šæœ¬çœŒ": "43000",
            "å¤§åˆ†": "44000", "å¤§åˆ†çœŒ": "44000",
            "å®®å´": "45000", "å®®å´çœŒ": "45000",
            "é¹¿å…å³¶": "46000", "é¹¿å…å³¶çœŒ": "46000",
            "æ²–ç¸„": "47000", "æ²–ç¸„çœŒ": "47000",
        }
        
        # çµ±è¨ˆé …ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        self.stats_keywords = {
            "äººå£": ["å›½å‹¢èª¿æŸ»", "äººå£æ¨è¨ˆ", "ä½æ°‘åŸºæœ¬å°å¸³"],
            "å¤±æ¥­ç‡": ["åŠ´åƒåŠ›èª¿æŸ»", "å®Œå…¨å¤±æ¥­ç‡"],
            "é›‡ç”¨": ["åŠ´åƒåŠ›èª¿æŸ»", "å°±æ¥­æ§‹é€ åŸºæœ¬èª¿æŸ»"],
            "è³ƒé‡‘": ["æ¯æœˆå‹¤åŠ´çµ±è¨ˆ", "è³ƒé‡‘æ§‹é€ åŸºæœ¬çµ±è¨ˆ"],
            "ç‰©ä¾¡": ["æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°", "ä¼æ¥­ç‰©ä¾¡æŒ‡æ•°"],
            "GDP": ["å›½æ°‘çµŒæ¸ˆè¨ˆç®—", "GDP"],
            "å®¶è¨ˆ": ["å®¶è¨ˆèª¿æŸ»", "å®¶è¨ˆåæ”¯"],
            "ä¼æ¥­": ["æ³•äººä¼æ¥­çµ±è¨ˆ", "ä¼æ¥­æ´»å‹•åŸºæœ¬èª¿æŸ»"],
            "å»ºè¨­": ["å»ºè¨­å·¥äº‹çµ±è¨ˆ", "å»ºç¯‰ç€å·¥çµ±è¨ˆ"],
            "è¾²æ¥­": ["è¾²æ—æ¥­ã‚»ãƒ³ã‚µã‚¹", "ä½œç‰©çµ±è¨ˆ"],
            "å·¥æ¥­": ["å·¥æ¥­çµ±è¨ˆ", "é‰±å·¥æ¥­æŒ‡æ•°"],
            "å•†æ¥­": ["å•†æ¥­çµ±è¨ˆ", "å•†æ¥­è²©å£²çµ±è¨ˆ"],
        }
        
        # ã‚ˆãä½¿ã‚ã‚Œã‚‹çµ±è¨ˆè¡¨ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆå®Ÿéš›ã®é‹ç”¨ã§ã¯å‹•çš„ã«æ§‹ç¯‰ï¼‰
        self.sample_stats_tables = [
            {
                "stats_data_id": "0000020101",
                "table_name": "äººå£æ¨è¨ˆ",
                "description": "äººå£æ¨è¨ˆï¼ˆæœˆå ±ï¼‰",
                "keywords": ["äººå£", "æ¨è¨ˆ"],
                "available_areas": ["å…¨å›½", "éƒ½é“åºœçœŒ"],
                "categories": {
                    "cdCat01": {"001": "ç·äººå£", "002": "ç”·", "003": "å¥³"},
                    "cdCat02": {"01": "ç·æ•°", "02": "0ï½14æ­³", "03": "15ï½64æ­³", "04": "65æ­³ä»¥ä¸Š"}
                }
            },
            {
                "stats_data_id": "0003084821",
                "table_name": "å›½å‹¢èª¿æŸ»",
                "description": "äººå£ç­‰åŸºæœ¬é›†è¨ˆï¼ˆå¹´é½¢ãƒ»ç”·å¥³åˆ¥äººå£ï¼‰",
                "keywords": ["äººå£", "å¹´é½¢", "ç”·å¥³"],
                "available_areas": ["å…¨å›½", "éƒ½é“åºœçœŒ", "å¸‚åŒºç”ºæ‘"],
                "categories": {
                    "cdCat01": {"01000": "ç·æ•°", "01001": "0æ­³", "01002": "1æ­³"},
                    "cdCat02": {"001": "ç·æ•°", "002": "ç”·", "003": "å¥³"}
                }
            },
            {
                "stats_data_id": "0003191203",
                "table_name": "åŠ´åƒåŠ›èª¿æŸ»",
                "description": "åŠ´åƒåŠ›èª¿æŸ»ï¼ˆåŸºæœ¬é›†è¨ˆï¼‰",
                "keywords": ["åŠ´åƒ", "é›‡ç”¨", "å¤±æ¥­ç‡"],
                "available_areas": ["å…¨å›½"],
                "categories": {
                    "cdCat01": {"11020": "å®Œå…¨å¤±æ¥­ç‡", "10101": "å°±æ¥­è€…æ•°"},
                    "cdCat02": {"001": "ç·æ•°", "002": "ç”·", "003": "å¥³"}
                }
            }
        ]
    
    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        if not self.db_path.exists():
            self._create_database()
        
    def _create_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # çµ±è¨ˆè¡¨æƒ…å ±ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE stats_tables (
                stats_data_id TEXT PRIMARY KEY,
                table_name TEXT NOT NULL,
                description TEXT,
                organization TEXT,
                field_code TEXT,
                field_name TEXT,
                keywords TEXT,
                available_areas TEXT,
                categories TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
        for table in self.sample_stats_tables:
            cursor.execute('''
                INSERT INTO stats_tables 
                (stats_data_id, table_name, description, keywords, available_areas, categories)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                table["stats_data_id"],
                table["table_name"],
                table["description"],
                json.dumps(table["keywords"]),
                json.dumps(table["available_areas"]),
                json.dumps(table["categories"])
            ))
        
        conn.commit()
        conn.close()
    
    def parse_query(self, query: str) -> EntitySet:
        """è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã‚’è§£æã—ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æŠ½å‡º"""
        query = query.strip()
        
        # åœ°åŸŸåã®æŠ½å‡º
        regions = []
        for region_name, region_code in self.area_mappings.items():
            if region_name in query:
                regions.append(region_name)
        
        # çµ±è¨ˆé …ç›®ã®æŠ½å‡º
        statistical_items = []
        for item, keywords in self.stats_keywords.items():
            if item in query or any(keyword in query for keyword in keywords):
                statistical_items.append(item)
        
        # æ™‚é–“æœŸé–“ã®æŠ½å‡ºï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        time_periods = []
        year_pattern = r'(\d{4})å¹´?'
        years = re.findall(year_pattern, query)
        time_periods.extend(years)
        
        if "æœ€æ–°" in query or "æœ€è¿‘" in query:
            time_periods.append("latest")
        
        # åˆ†é¡ã®æŠ½å‡º
        categories = []
        if "å¹´é½¢" in query or "å¹´ä»£" in query:
            categories.append("age")
        if "ç”·å¥³" in query or "æ€§åˆ¥" in query:
            categories.append("gender")
        if "ç”£æ¥­" in query or "æ¥­ç¨®" in query:
            categories.append("industry")
        
        return EntitySet(
            regions=regions,
            time_periods=time_periods,
            categories=categories,
            statistical_items=statistical_items
        )
    
    def search_stats_tables(self, entities: EntitySet) -> List[Dict]:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«åŸºã¥ã„ã¦çµ±è¨ˆè¡¨ã‚’æ¤œç´¢"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢
        search_terms = entities.statistical_items
        
        if not search_terms:
            # çµ±è¨ˆé …ç›®ãŒç‰¹å®šã§ããªã„å ´åˆã¯å…¨ä½“ã‚’æ¤œç´¢
            cursor.execute('SELECT * FROM stats_tables')
        else:
            # ORæ¤œç´¢ã§ãƒãƒƒãƒã™ã‚‹çµ±è¨ˆè¡¨ã‚’æ¢ã™
            placeholders = ' OR '.join(['keywords LIKE ?'] * len(search_terms))
            search_values = [f'%{term}%' for term in search_terms]
            
            cursor.execute(f'''
                SELECT * FROM stats_tables 
                WHERE {placeholders}
                ORDER BY stats_data_id
            ''', search_values)
        
        results = []
        for row in cursor.fetchall():
            results.append({
                'stats_data_id': row[0],
                'table_name': row[1],
                'description': row[2],
                'organization': row[3],
                'field_code': row[4],
                'field_name': row[5],
                'keywords': json.loads(row[6]) if row[6] else [],
                'available_areas': json.loads(row[7]) if row[7] else [],
                'categories': json.loads(row[8]) if row[8] else {}
            })
        
        conn.close()
        return results
    
    def generate_parameters(self, entities: EntitySet, table_info: Dict) -> Dict[str, str]:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æƒ…å ±ã‹ã‚‰ APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        parameters = {}
        
        # åœ°åŸŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        if entities.regions:
            region_name = entities.regions[0]  # æœ€åˆã®åœ°åŸŸã‚’ä½¿ç”¨
            if region_name in self.area_mappings:
                area_code = self.area_mappings[region_name]
                parameters["cdArea"] = area_code
        
        # åˆ†é¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        categories = table_info.get("categories", {})
        
        # æ€§åˆ¥ã®æŒ‡å®š
        if "gender" in entities.categories and "cdCat02" in categories:
            parameters["cdCat02"] = "002,003"  # ç”·ã€å¥³
        
        # å¹´é½¢ã®æŒ‡å®š
        if "age" in entities.categories and "cdCat01" in categories:
            # å¹´é½¢éšç´šã‚’æŒ‡å®šï¼ˆã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦ï¼‰
            parameters["cdCat01"] = "01000-01021"  # 0æ­³ã€œ100æ­³ä»¥ä¸Š
        
        # æ™‚é–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        if entities.time_periods:
            if "latest" in entities.time_periods:
                # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å‹•çš„ã«æ±ºå®šï¼‰
                parameters["cdTime"] = "2024000000"
            else:
                # æŒ‡å®šå¹´ã®ãƒ‡ãƒ¼ã‚¿
                year = entities.time_periods[0]
                parameters["cdTime"] = f"{year}000000"
        
        return parameters
    
    def calculate_confidence(self, entities: EntitySet, table_info: Dict) -> float:
        """ãƒãƒƒãƒãƒ³ã‚°ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—"""
        score = 0.0
        
        # çµ±è¨ˆé …ç›®ã®ãƒãƒƒãƒåº¦
        table_keywords = table_info.get("keywords", [])
        matched_items = len(set(entities.statistical_items) & set(table_keywords))
        if entities.statistical_items:
            score += (matched_items / len(entities.statistical_items)) * 0.6
        
        # åœ°åŸŸã®å¯¾å¿œåº¦
        if entities.regions:
            available_areas = table_info.get("available_areas", [])
            if any(region in available_areas for region in entities.regions):
                score += 0.3
        else:
            score += 0.2  # åœ°åŸŸæŒ‡å®šãªã—ã®å ´åˆã¯ä¸­ç¨‹åº¦ã®ã‚¹ã‚³ã‚¢
        
        # åˆ†é¡ã®å¯¾å¿œåº¦
        if entities.categories:
            categories = table_info.get("categories", {})
            if categories:
                score += 0.1
        
        return min(score, 1.0)
    
    def translate_query(self, query: str, limit: int = 5) -> List[QueryResult]:
        """è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã‚’ e-stat APIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›"""
        
        # Ollamaçµ±åˆã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
        if self.ollama_mcp and self.ollama_mcp.available:
            return self._translate_with_ollama(query, limit)
        else:
            return self._translate_with_rules(query, limit)
    
    def _translate_with_ollama(self, query: str, limit: int = 5) -> List[QueryResult]:
        """Ollamaçµ±åˆã‚’ä½¿ç”¨ã—ãŸã‚¯ã‚¨ãƒªå¤‰æ›"""
        print("ğŸ¤– Ollama AIã«ã‚ˆã‚‹çµ±è¨ˆè¡¨ãƒ»è»¸æƒ…å ±ã®ææ¡ˆ...")
        
        # 1. ã‚¯ã‚¨ãƒªã‚’è§£æã—ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æŠ½å‡ºï¼ˆåŸºæœ¬æƒ…å ±ã¨ã—ã¦ï¼‰
        entities = self.parse_query(query)
        
        # 2. Ollamaã«AIææ¡ˆã‚’ä¾é ¼
        region = entities.regions[0] if entities.regions else None
        time_period = entities.time_periods[0] if entities.time_periods else None
        
        ollama_response = self.ollama_mcp.suggest_stats_table_and_axes(
            query=query,
            region=region,
            time_period=time_period
        )
        
        # 3. Ollamaææ¡ˆã«åŸºã¥ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆ
        ai_parameters = self._generate_ai_parameters(entities, ollama_response)
        
        # 4. ãƒ¡ã‚¤ãƒ³çµæœã‚’ä½œæˆ
        main_result = QueryResult(
            stats_data_id=ollama_response.stats_table_id,
            parameters=ai_parameters,
            description=f"AIææ¡ˆ: {ollama_response.table_name}",
            confidence_score=min(ollama_response.confidence, 1.0),
            table_name=ollama_response.table_name
        )
        
        print(f"ğŸ¯ AIææ¡ˆçµæœ: {ollama_response.table_name} (ä¿¡é ¼åº¦: {ollama_response.confidence:.2f})")
        print(f"ğŸ” AIé¸æŠç†ç”±: {ollama_response.reasoning}")
        print(f"ğŸ”§ ææ¡ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {ai_parameters}")
        
        # 5. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€™è£œã‚‚ç”Ÿæˆï¼ˆå¾“æ¥æ‰‹æ³•ï¼‰
        fallback_results = self._translate_with_rules(query, limit-1)
        
        # 6. ä»£æ›¿æ¡ˆã¨ã—ã¦è¨­å®š
        main_result.alternative_suggestions = fallback_results
        
        return [main_result]
    
    def _translate_with_rules(self, query: str, limit: int = 5) -> List[QueryResult]:
        """å¾“æ¥ã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªå¤‰æ›"""
        # 1. ã‚¯ã‚¨ãƒªã‚’è§£æã—ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æŠ½å‡º
        entities = self.parse_query(query)
        
        # 2. ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«åŸºã¥ã„ã¦çµ±è¨ˆè¡¨ã‚’æ¤œç´¢
        candidate_tables = self.search_stats_tables(entities)
        
        # 3. å„å€™è£œã«å¯¾ã—ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        results = []
        for table_info in candidate_tables[:limit]:
            parameters = self.generate_parameters(entities, table_info)
            confidence = self.calculate_confidence(entities, table_info)
            
            result = QueryResult(
                stats_data_id=table_info["stats_data_id"],
                parameters=parameters,
                description=table_info["description"],
                confidence_score=confidence,
                table_name=table_info["table_name"]
            )
            results.append(result)
        
        # 4. ä¿¡é ¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x.confidence_score, reverse=True)
        
        # 5. ä»£æ›¿æ¡ˆã®è¨­å®š
        if results:
            main_result = results[0]
            main_result.alternative_suggestions = results[1:]
            return [main_result]
        
        return results
    
    def _generate_ai_parameters(self, entities: EntitySet, ollama_response) -> Dict[str, str]:
        """AIææ¡ˆã«åŸºã¥ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆ"""
        parameters = {}
        
        # åœ°åŸŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        if entities.regions and "cdArea" in ollama_response.axis_mappings:
            region_name = entities.regions[0]
            if region_name in self.area_mappings:
                parameters["cdArea"] = self.area_mappings[region_name]
        
        # æ™‚é–“ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        if entities.time_periods and "cdTime" in ollama_response.axis_mappings:
            if "latest" in entities.time_periods:
                parameters["cdTime"] = "2024000000"
            else:
                year = entities.time_periods[0]
                if year.isdigit():
                    parameters["cdTime"] = f"{year}000000"
        
        # åˆ†é¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆAIã®è»¸ãƒãƒƒãƒ”ãƒ³ã‚°ææ¡ˆã«åŸºã¥ãï¼‰
        for axis_code, axis_description in ollama_response.axis_mappings.items():
            if axis_code.startswith("cdCat"):
                # æ€§åˆ¥ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
                if "gender" in entities.categories and "ç”·å¥³" in axis_description:
                    parameters[axis_code] = "002,003"  # ç”·æ€§ã€å¥³æ€§
                # å¹´é½¢ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
                elif "age" in entities.categories and "å¹´é½¢" in axis_description:
                    parameters[axis_code] = "01000"  # ç·æ•°ï¼ˆè©³ç´°ã¯å¾Œã§æŒ‡å®šï¼‰
        
        return parameters
    
    def get_query_suggestions(self, partial_query: str) -> List[str]:
        """éƒ¨åˆ†çš„ãªã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹è£œå®Œå€™è£œã‚’æä¾›"""
        suggestions = []
        
        # åœ°åŸŸåã®å€™è£œ
        for region in self.area_mappings.keys():
            if region.startswith(partial_query):
                suggestions.append(f"{region}ã®äººå£ãƒ‡ãƒ¼ã‚¿")
                suggestions.append(f"{region}ã®é›‡ç”¨çµ±è¨ˆ")
        
        # çµ±è¨ˆé …ç›®ã®å€™è£œ
        for item in self.stats_keywords.keys():
            if item.startswith(partial_query):
                suggestions.append(f"{item}ã®æ¨ç§»")
                suggestions.append(f"éƒ½é“åºœçœŒåˆ¥{item}")
        
        return suggestions[:10]  # æœ€å¤§10ä»¶


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def main():
    """ä½¿ç”¨ä¾‹"""
    translator = EstatQueryTranslator()
    
    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_queries = [
        "æ±äº¬éƒ½ã®å¹´é½¢åˆ¥äººå£ãŒçŸ¥ã‚ŠãŸã„",
        "æœ€æ–°ã®å®Œå…¨å¤±æ¥­ç‡ã‚’è¦‹ãŸã„", 
        "éƒ½é“åºœçœŒåˆ¥ã®äººå£ã‚’æ¯”è¼ƒã—ãŸã„",
        "2020å¹´ã®ç”·å¥³åˆ¥äººå£ãƒ‡ãƒ¼ã‚¿"
    ]
    
    for query in test_queries:
        print(f"\n=== ã‚¯ã‚¨ãƒª: {query} ===")
        results = translator.translate_query(query)
        
        if results:
            result = results[0]
            print(f"çµ±è¨ˆè¡¨ID: {result.stats_data_id}")
            print(f"è¡¨å: {result.table_name}")
            print(f"èª¬æ˜: {result.description}")
            print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {result.parameters}")
            print(f"ä¿¡é ¼åº¦: {result.confidence_score:.2f}")
            
            if result.alternative_suggestions:
                print("\nä»£æ›¿æ¡ˆ:")
                for alt in result.alternative_suggestions:
                    print(f"  - {alt.table_name} (ä¿¡é ¼åº¦: {alt.confidence_score:.2f})")
        else:
            print("è©²å½“ã™ã‚‹çµ±è¨ˆè¡¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    main()